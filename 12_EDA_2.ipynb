{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 12: Data Preprocessing and Feature Engineering\n",
    "\n",
    "## Dataset: Adult Census Income\n",
    "Predicts whether income exceeds $50K/yr based on census data.\n",
    "\n",
    "**Topics Covered:**\n",
    "- Data Exploration and Preprocessing\n",
    "- Scaling (Standard & Min-Max)\n",
    "- Encoding (One-Hot & Label)\n",
    "- Feature Engineering\n",
    "- Feature Selection (Isolation Forest, PPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n",
      "Shape: (1000, 15)\n",
      "\n",
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>Federal-gov</td>\n",
       "      <td>1015558</td>\n",
       "      <td>Masters</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>68000</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>511907</td>\n",
       "      <td>Masters</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>94000</td>\n",
       "      <td>200</td>\n",
       "      <td>21</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>1370445</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>16000</td>\n",
       "      <td>3000</td>\n",
       "      <td>42</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89</td>\n",
       "      <td>Federal-gov</td>\n",
       "      <td>155060</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>Amer-Indian-Eskimo</td>\n",
       "      <td>Female</td>\n",
       "      <td>80000</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76</td>\n",
       "      <td>Without-pay</td>\n",
       "      <td>629017</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>2</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     workclass   fnlwgt  education  education_num      marital_status  \\\n",
       "0   22   Federal-gov  1015558    Masters             13  Married-civ-spouse   \n",
       "1   53     State-gov   511907    Masters              9            Divorced   \n",
       "2   78  Self-emp-inc  1370445    HS-grad              9             Widowed   \n",
       "3   89   Federal-gov   155060    HS-grad              9             Widowed   \n",
       "4   76   Without-pay   629017  Doctorate              2           Separated   \n",
       "\n",
       "          occupation    relationship                race     sex  \\\n",
       "0    Exec-managerial   Not-in-family               Black    Male   \n",
       "1              Sales  Other-relative               Black  Female   \n",
       "2  Machine-op-inspct         Husband               Black  Female   \n",
       "3       Craft-repair  Other-relative  Amer-Indian-Eskimo  Female   \n",
       "4  Machine-op-inspct  Other-relative               White    Male   \n",
       "\n",
       "   capital_gain  capital_loss  hours_per_week native_country income  \n",
       "0         68000             0              47    Philippines  <=50K  \n",
       "1         94000           200              21    Philippines   >50K  \n",
       "2         16000          3000              42    Philippines  <=50K  \n",
       "3         80000             0              70    Philippines   >50K  \n",
       "4             0             0              89         Mexico  <=50K  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('datasets/adult_with_headers.csv')\n",
    "\n",
    "# Display basic info\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 1: Data Exploration and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Data Types ===\n",
      "age                int64\n",
      "workclass         object\n",
      "fnlwgt             int64\n",
      "education         object\n",
      "education_num      int64\n",
      "marital_status    object\n",
      "occupation        object\n",
      "relationship      object\n",
      "race              object\n",
      "sex               object\n",
      "capital_gain       int64\n",
      "capital_loss       int64\n",
      "hours_per_week     int64\n",
      "native_country    object\n",
      "income            object\n",
      "dtype: object\n",
      "\n",
      "=== Summary Statistics ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education_num</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>52.787000</td>\n",
       "      <td>7.416421e+05</td>\n",
       "      <td>7.838000</td>\n",
       "      <td>27323.000000</td>\n",
       "      <td>880.400000</td>\n",
       "      <td>48.568000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>21.370829</td>\n",
       "      <td>4.301271e+05</td>\n",
       "      <td>4.210164</td>\n",
       "      <td>32745.365014</td>\n",
       "      <td>1471.339757</td>\n",
       "      <td>27.800256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.057100e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>3.840932e+05</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>52.000000</td>\n",
       "      <td>7.279875e+05</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>72.000000</td>\n",
       "      <td>1.113147e+06</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>55000.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>71.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>89.000000</td>\n",
       "      <td>1.492962e+06</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>99000.000000</td>\n",
       "      <td>4900.000000</td>\n",
       "      <td>98.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age        fnlwgt  education_num  capital_gain  capital_loss  \\\n",
       "count  1000.000000  1.000000e+03    1000.000000   1000.000000   1000.000000   \n",
       "mean     52.787000  7.416421e+05       7.838000  27323.000000    880.400000   \n",
       "std      21.370829  4.301271e+05       4.210164  32745.365014   1471.339757   \n",
       "min      17.000000  1.057100e+04       1.000000      0.000000      0.000000   \n",
       "25%      34.000000  3.840932e+05       4.000000      0.000000      0.000000   \n",
       "50%      52.000000  7.279875e+05       8.000000   7000.000000      0.000000   \n",
       "75%      72.000000  1.113147e+06      11.000000  55000.000000   1500.000000   \n",
       "max      89.000000  1.492962e+06      15.000000  99000.000000   4900.000000   \n",
       "\n",
       "       hours_per_week  \n",
       "count     1000.000000  \n",
       "mean        48.568000  \n",
       "std         27.800256  \n",
       "min          1.000000  \n",
       "25%         24.000000  \n",
       "50%         49.000000  \n",
       "75%         71.000000  \n",
       "max         98.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic data exploration\n",
    "print(\"=== Data Types ===\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\n=== Summary Statistics ===\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Missing Values ===\n",
      "\n",
      "Null values:\n",
      "age               0\n",
      "workclass         0\n",
      "fnlwgt            0\n",
      "education         0\n",
      "education_num     0\n",
      "marital_status    0\n",
      "occupation        0\n",
      "relationship      0\n",
      "race              0\n",
      "sex               0\n",
      "capital_gain      0\n",
      "capital_loss      0\n",
      "hours_per_week    0\n",
      "native_country    0\n",
      "income            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"=== Missing Values ===\")\n",
    "\n",
    "# In this dataset, missing values are represented as ' ?' (with space)\n",
    "# Let's check for this pattern\n",
    "for column in df.columns:\n",
    "    # Check for ' ?' pattern\n",
    "    if df[column].dtype == 'object':\n",
    "        missing_count = (df[column].str.strip() == '?').sum()\n",
    "        if missing_count > 0:\n",
    "            print(column + \":\", missing_count, \"missing values\")\n",
    "\n",
    "# Also check for regular null values\n",
    "print(\"\\nNull values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Handling Missing Values ===\n",
      "\n",
      "Remaining missing values: 0\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values (replace '?' with NaN then fill with mode)\n",
    "print(\"=== Handling Missing Values ===\")\n",
    "\n",
    "# Clean string columns by stripping whitespace\n",
    "for column in df.columns:\n",
    "    if df[column].dtype == 'object':\n",
    "        df[column] = df[column].str.strip()\n",
    "        # Replace '?' with NaN\n",
    "        df[column] = df[column].replace('?', np.nan)\n",
    "\n",
    "# Fill missing values with mode (most frequent value)\n",
    "for column in df.columns:\n",
    "    missing_count = df[column].isnull().sum()\n",
    "    if missing_count > 0:\n",
    "        mode_value = df[column].mode()[0]\n",
    "        df[column] = df[column].fillna(mode_value)\n",
    "        print(\"Filled\", missing_count, \"missing values in\", column, \"with mode:\", mode_value)\n",
    "\n",
    "print(\"\\nRemaining missing values:\", df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Scaling Techniques\n",
    "\n",
    "**Standard Scaling:** Transforms data to have mean=0 and std=1\n",
    "- Best when: Data is normally distributed, algorithm uses distance measures\n",
    "\n",
    "**Min-Max Scaling:** Transforms data to range [0, 1]\n",
    "- Best when: You need bounded values, neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data (first 5 rows):\n",
      "   age   fnlwgt  education_num  capital_gain  capital_loss  hours_per_week\n",
      "0   22  1015558             13         68000             0              47\n",
      "1   53   511907              9         94000           200              21\n",
      "2   78  1370445              9         16000          3000              42\n",
      "3   89   155060              9         80000             0              70\n",
      "4   76   629017              2             0             0              89\n"
     ]
    }
   ],
   "source": [
    "# Identify numerical columns\n",
    "numerical_columns = ['age', 'fnlwgt', 'education_num', 'capital_gain', 'capital_loss', 'hours_per_week']\n",
    "\n",
    "print(\"Original Data (first 5 rows):\")\n",
    "print(df[numerical_columns].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Standard Scaling ===\n",
      "After Standard Scaling:\n",
      "    age_std  fnlwgt_std  education_num_std  capital_gain_std  \\\n",
      "0 -1.440609    0.636825           1.226080          1.242222   \n",
      "1  0.009967   -0.534110           0.275999          2.036227   \n",
      "2  1.179786    1.461900           0.275999         -0.345789   \n",
      "3  1.694506   -1.363741           0.275999          1.608686   \n",
      "4  1.086200   -0.261841          -1.386644         -0.834408   \n",
      "\n",
      "   capital_loss_std  hours_per_week_std  \n",
      "0         -0.598366           -0.056402  \n",
      "1         -0.462436           -0.991646  \n",
      "2          1.440592           -0.236257  \n",
      "3         -0.598366            0.770928  \n",
      "4         -0.598366            1.454375  \n",
      "\n",
      "Verification (mean should be ~0, std should be ~1):\n",
      "age_std - Mean: 0.0 Std: 1.0\n",
      "fnlwgt_std - Mean: 0.0 Std: 1.0\n",
      "education_num_std - Mean: -0.0 Std: 1.0\n",
      "capital_gain_std - Mean: -0.0 Std: 1.0\n",
      "capital_loss_std - Mean: 0.0 Std: 1.0\n",
      "hours_per_week_std - Mean: 0.0 Std: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Standard Scaling\n",
    "print(\"=== Standard Scaling ===\")\n",
    "\n",
    "# Create a copy for standard scaling\n",
    "df_standard = df.copy()\n",
    "\n",
    "# Apply standard scaling manually (to show the process)\n",
    "for column in numerical_columns:\n",
    "    mean_val = df[column].mean()\n",
    "    std_val = df[column].std()\n",
    "    df_standard[column + '_std'] = (df[column] - mean_val) / std_val\n",
    "\n",
    "print(\"After Standard Scaling:\")\n",
    "std_cols = [col + '_std' for col in numerical_columns]\n",
    "print(df_standard[std_cols].head())\n",
    "\n",
    "print(\"\\nVerification (mean should be ~0, std should be ~1):\")\n",
    "for col in std_cols:\n",
    "    print(col, \"- Mean:\", round(df_standard[col].mean(), 4), \"Std:\", round(df_standard[col].std(), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Min-Max Scaling ===\n",
      "After Min-Max Scaling:\n",
      "     age_mm  fnlwgt_mm  education_num_mm  capital_gain_mm  capital_loss_mm  \\\n",
      "0  0.069444   0.677950          0.857143         0.686869         0.000000   \n",
      "1  0.500000   0.338194          0.571429         0.949495         0.040816   \n",
      "2  0.847222   0.917352          0.571429         0.161616         0.612245   \n",
      "3  1.000000   0.097470          0.571429         0.808081         0.000000   \n",
      "4  0.819444   0.417195          0.071429         0.000000         0.000000   \n",
      "\n",
      "   hours_per_week_mm  \n",
      "0           0.474227  \n",
      "1           0.206186  \n",
      "2           0.422680  \n",
      "3           0.711340  \n",
      "4           0.907216  \n",
      "\n",
      "Verification (min should be 0, max should be 1):\n",
      "age_mm - Min: 0.0 Max: 1.0\n",
      "fnlwgt_mm - Min: 0.0 Max: 1.0\n",
      "education_num_mm - Min: 0.0 Max: 1.0\n",
      "capital_gain_mm - Min: 0.0 Max: 1.0\n",
      "capital_loss_mm - Min: 0.0 Max: 1.0\n",
      "hours_per_week_mm - Min: 0.0 Max: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Min-Max Scaling\n",
    "print(\"=== Min-Max Scaling ===\")\n",
    "\n",
    "# Create a copy for min-max scaling\n",
    "df_minmax = df.copy()\n",
    "\n",
    "# Apply min-max scaling manually\n",
    "for column in numerical_columns:\n",
    "    min_val = df[column].min()\n",
    "    max_val = df[column].max()\n",
    "    df_minmax[column + '_mm'] = (df[column] - min_val) / (max_val - min_val)\n",
    "\n",
    "print(\"After Min-Max Scaling:\")\n",
    "mm_cols = [col + '_mm' for col in numerical_columns]\n",
    "print(df_minmax[mm_cols].head())\n",
    "\n",
    "print(\"\\nVerification (min should be 0, max should be 1):\")\n",
    "for col in mm_cols:\n",
    "    print(col, \"- Min:\", round(df_minmax[col].min(), 4), \"Max:\", round(df_minmax[col].max(), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When to use which scaling:**\n",
    "\n",
    "| Standard Scaling | Min-Max Scaling |\n",
    "|-----------------|----------------|\n",
    "| Data is normally distributed | Data needs to be in [0,1] range |\n",
    "| Algorithms: SVM, Logistic Regression | Algorithms: Neural Networks, KNN |\n",
    "| Not affected by outliers much | Sensitive to outliers |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 2: Encoding Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Unique Values in Categorical Columns ===\n",
      "workclass: 7 unique values\n",
      "education: 7 unique values\n",
      "marital_status: 5 unique values\n",
      "occupation: 6 unique values\n",
      "relationship: 6 unique values\n",
      "race: 5 unique values\n",
      "sex: 2 unique values\n",
      "native_country: 6 unique values\n",
      "income: 2 unique values\n"
     ]
    }
   ],
   "source": [
    "# Identify categorical columns\n",
    "categorical_columns = ['workclass', 'education', 'marital_status', 'occupation', \n",
    "                       'relationship', 'race', 'sex', 'native_country', 'income']\n",
    "\n",
    "# Count unique values in each categorical column\n",
    "print(\"=== Unique Values in Categorical Columns ===\")\n",
    "for column in categorical_columns:\n",
    "    unique_count = df[column].nunique()\n",
    "    print(column + \":\", unique_count, \"unique values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-Hot Encoding columns (< 5 categories):\n",
      "['sex', 'income']\n",
      "\n",
      "Label Encoding columns (>= 5 categories):\n",
      "['workclass', 'education', 'marital_status', 'occupation', 'relationship', 'race', 'native_country']\n"
     ]
    }
   ],
   "source": [
    "# Separate columns based on unique values\n",
    "# Less than 5 categories -> One-Hot Encoding\n",
    "# 5 or more categories -> Label Encoding\n",
    "\n",
    "one_hot_columns = []  # < 5 categories\n",
    "label_encode_columns = []  # >= 5 categories\n",
    "\n",
    "for column in categorical_columns:\n",
    "    unique_count = df[column].nunique()\n",
    "    if unique_count < 5:\n",
    "        one_hot_columns.append(column)\n",
    "    else:\n",
    "        label_encode_columns.append(column)\n",
    "\n",
    "print(\"One-Hot Encoding columns (< 5 categories):\")\n",
    "print(one_hot_columns)\n",
    "\n",
    "print(\"\\nLabel Encoding columns (>= 5 categories):\")\n",
    "print(label_encode_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== One-Hot Encoding ===\n",
      "Original shape: (1000, 15)\n",
      "After One-Hot Encoding: (1000, 17)\n",
      "\n",
      "New columns created:\n",
      " - sex_Female\n",
      " - sex_Male\n",
      " - income_<=50K\n",
      " - income_>50K\n"
     ]
    }
   ],
   "source": [
    "# One-Hot Encoding\n",
    "print(\"=== One-Hot Encoding ===\")\n",
    "\n",
    "df_encoded = df.copy()\n",
    "\n",
    "# Apply one-hot encoding using pandas get_dummies\n",
    "df_encoded = pd.get_dummies(df_encoded, columns=one_hot_columns)\n",
    "\n",
    "print(\"Original shape:\", df.shape)\n",
    "print(\"After One-Hot Encoding:\", df_encoded.shape)\n",
    "\n",
    "# Show new columns created\n",
    "new_cols = [col for col in df_encoded.columns if col not in df.columns]\n",
    "print(\"\\nNew columns created:\")\n",
    "for col in new_cols[:10]:\n",
    "    print(\" -\", col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Label Encoding ===\n",
      "\n",
      "Encoding: workclass\n",
      "Original values: ['Federal-gov' 'State-gov' 'Self-emp-inc' 'Without-pay' 'Local-gov'] ...\n",
      "Encoded values: [0 1 2 3 4] ...\n",
      "\n",
      "Encoding: education\n",
      "Original values: ['Masters' 'HS-grad' 'Doctorate' 'Some-college' 'Bachelors'] ...\n",
      "Encoded values: [0 1 2 3 4] ...\n",
      "\n",
      "Encoding: marital_status\n",
      "Original values: ['Married-civ-spouse' 'Divorced' 'Widowed' 'Separated' 'Never-married'] ...\n",
      "Encoded values: [0 1 2 3 4] ...\n",
      "\n",
      "Encoding: occupation\n",
      "Original values: ['Exec-managerial' 'Sales' 'Machine-op-inspct' 'Craft-repair'\n",
      " 'Tech-support'] ...\n",
      "Encoded values: [0 1 2 3 4] ...\n",
      "\n",
      "Encoding: relationship\n",
      "Original values: ['Not-in-family' 'Other-relative' 'Husband' 'Unmarried' 'Own-child'] ...\n",
      "Encoded values: [0 1 2 3 4] ...\n",
      "\n",
      "Encoding: race\n",
      "Original values: ['Black' 'Amer-Indian-Eskimo' 'White' 'Other' 'Asian-Pac-Islander'] ...\n",
      "Encoded values: [0 1 2 3 4] ...\n",
      "\n",
      "Encoding: native_country\n",
      "Original values: ['Philippines' 'Mexico' 'Canada' 'India' 'United-States'] ...\n",
      "Encoded values: [0 1 2 3 4] ...\n",
      "\n",
      "Label Encoding complete!\n"
     ]
    }
   ],
   "source": [
    "# Label Encoding\n",
    "print(\"=== Label Encoding ===\")\n",
    "\n",
    "# Apply label encoding\n",
    "for column in label_encode_columns:\n",
    "    print(\"\\nEncoding:\", column)\n",
    "    print(\"Original values:\", df_encoded[column].unique()[:5], \"...\")\n",
    "    \n",
    "    # Create mapping dictionary\n",
    "    unique_values = df_encoded[column].unique()\n",
    "    mapping = {}\n",
    "    for i in range(len(unique_values)):\n",
    "        mapping[unique_values[i]] = i\n",
    "    \n",
    "    # Apply mapping\n",
    "    df_encoded[column] = df_encoded[column].map(mapping)\n",
    "    print(\"Encoded values:\", df_encoded[column].unique()[:5], \"...\")\n",
    "\n",
    "print(\"\\nLabel Encoding complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pros and Cons:**\n",
    "\n",
    "| One-Hot Encoding | Label Encoding |\n",
    "|-----------------|----------------|\n",
    "| **Pros:** No ordinal assumption | **Pros:** Simple, no extra columns |\n",
    "| **Pros:** Works with all algorithms | **Pros:** Memory efficient |\n",
    "| **Cons:** Creates many columns | **Cons:** Implies ordinal relationship |\n",
    "| **Cons:** Memory intensive | **Cons:** May mislead some algorithms |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 3: Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Feature Engineering ===\n",
      "Feature 1: total_capital = capital_gain - capital_loss\n",
      "This shows the net financial impact of capital transactions.\n",
      "Sample values: [68000, 93800, 13000, 80000, 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create new features\n",
    "print(\"=== Feature Engineering ===\")\n",
    "\n",
    "# Feature 1: Total Capital (gain - loss)\n",
    "# Rationale: Net capital change is more informative than separate gain/loss\n",
    "df['total_capital'] = df['capital_gain'] - df['capital_loss']\n",
    "print(\"Feature 1: total_capital = capital_gain - capital_loss\")\n",
    "print(\"This shows the net financial impact of capital transactions.\")\n",
    "print(\"Sample values:\", df['total_capital'].head().tolist())\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 2: age_group\n",
      "Rationale: Income patterns often differ by life stages.\n",
      "Age groups created:\n",
      "age_group\n",
      "Elder     338\n",
      "Middle    282\n",
      "Senior    261\n",
      "Young     119\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Feature 2: Age Group\n",
    "# Rationale: Income patterns often differ by age brackets\n",
    "print(\"Feature 2: age_group\")\n",
    "print(\"Rationale: Income patterns often differ by life stages.\")\n",
    "\n",
    "# Create age groups using simple if-else logic\n",
    "age_groups = []\n",
    "for age in df['age']:\n",
    "    if age < 25:\n",
    "        age_groups.append('Young')\n",
    "    elif age < 45:\n",
    "        age_groups.append('Middle')\n",
    "    elif age < 65:\n",
    "        age_groups.append('Senior')\n",
    "    else:\n",
    "        age_groups.append('Elder')\n",
    "\n",
    "df['age_group'] = age_groups\n",
    "print(\"Age groups created:\")\n",
    "print(df['age_group'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log Transformation on skewed feature\n",
    "print(\"=== Log Transformation ===\")\n",
    "\n",
    "# Check skewness of capital_gain\n",
    "print(\"Checking skewness of capital_gain:\")\n",
    "print(\"Mean:\", df['capital_gain'].mean())\n",
    "print(\"Median:\", df['capital_gain'].median())\n",
    "print(\"Skewness:\", df['capital_gain'].skew())\n",
    "\n",
    "# The large difference between mean and median indicates right skewness\n",
    "\n",
    "# Apply log transformation (adding 1 to avoid log(0))\n",
    "df['capital_gain_log'] = np.log1p(df['capital_gain'])\n",
    "\n",
    "print(\"\\nAfter log transformation:\")\n",
    "print(\"New skewness:\", df['capital_gain_log'].skew())\n",
    "\n",
    "# Visualize before and after\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axes[0].hist(df['capital_gain'], bins=50, color='blue', edgecolor='black')\n",
    "axes[0].set_title('Before: capital_gain')\n",
    "axes[0].set_xlabel('Value')\n",
    "\n",
    "axes[1].hist(df['capital_gain_log'], bins=50, color='green', edgecolor='black')\n",
    "axes[1].set_title('After: capital_gain_log')\n",
    "axes[1].set_xlabel('Log Value')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 4: Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Isolation Forest for Outlier Detection\n",
    "\n",
    "**Isolation Forest** identifies outliers by isolating observations.\n",
    "Outliers are easier to isolate and thus get shorter path lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Isolation Forest ===\n",
      "Total records: 1000\n",
      "Outliers detected: 50\n",
      "Inliers (normal): 950\n",
      "Outlier percentage: 5.0 %\n"
     ]
    }
   ],
   "source": [
    "# Isolation Forest for Outlier Detection\n",
    "print(\"=== Isolation Forest ===\")\n",
    "\n",
    "# Select numerical features for outlier detection\n",
    "features_for_outliers = df[numerical_columns].copy()\n",
    "\n",
    "# Create Isolation Forest model\n",
    "iso_forest = IsolationForest(contamination=0.05, random_state=42)\n",
    "\n",
    "# Fit and predict\n",
    "outlier_labels = iso_forest.fit_predict(features_for_outliers)\n",
    "\n",
    "# Count outliers (labeled as -1)\n",
    "outliers_count = 0\n",
    "inliers_count = 0\n",
    "for label in outlier_labels:\n",
    "    if label == -1:\n",
    "        outliers_count = outliers_count + 1\n",
    "    else:\n",
    "        inliers_count = inliers_count + 1\n",
    "\n",
    "print(\"Total records:\", len(outlier_labels))\n",
    "print(\"Outliers detected:\", outliers_count)\n",
    "print(\"Inliers (normal):\", inliers_count)\n",
    "print(\"Outlier percentage:\", round(outliers_count/len(outlier_labels)*100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 1000\n",
      "After removing outliers: 950\n",
      "\n",
      "=== How Outliers Affect Model Performance ===\n",
      "1. Outliers can skew model training towards extreme values\n",
      "2. Distance-based algorithms (KNN, SVM) are especially sensitive\n",
      "3. Outliers can increase model variance and reduce generalization\n",
      "4. They may represent data errors or rare but valid observations\n"
     ]
    }
   ],
   "source": [
    "# Create dataframe without outliers\n",
    "df['is_outlier'] = outlier_labels\n",
    "df_clean = df[df['is_outlier'] == 1].copy()\n",
    "\n",
    "print(\"Original dataset size:\", len(df))\n",
    "print(\"After removing outliers:\", len(df_clean))\n",
    "\n",
    "print(\"\\n=== How Outliers Affect Model Performance ===\")\n",
    "print(\"1. Outliers can skew model training towards extreme values\")\n",
    "print(\"2. Distance-based algorithms (KNN, SVM) are especially sensitive\")\n",
    "print(\"3. Outliers can increase model variance and reduce generalization\")\n",
    "print(\"4. They may represent data errors or rare but valid observations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Matrix\n",
    "print(\"=== Correlation Matrix ===\")\n",
    "\n",
    "# Select numerical columns for correlation\n",
    "numerical_data = df[numerical_columns + ['total_capital', 'capital_gain_log']]\n",
    "\n",
    "# Calculate correlation\n",
    "correlation_matrix = numerical_data.corr()\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 PPS (Predictive Power Score)\n",
    "\n",
    "**PPS** measures how well one variable can predict another.\n",
    "Unlike correlation, it:\n",
    "- Works with categorical variables\n",
    "- Captures non-linear relationships\n",
    "- Is asymmetric (A->B may differ from B->A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Predictive Power Analysis ===\n",
      "\n",
      "Education vs Income:\n",
      "Chi-square statistic: 3.41\n",
      "P-value: 0.7560921734230491\n",
      "\n",
      "Occupation vs Income:\n",
      "Chi-square statistic: 6.46\n",
      "P-value: 0.2641815813220281\n"
     ]
    }
   ],
   "source": [
    "# Simple PPS-like analysis using cross-tabulation\n",
    "# Note: Full PPS requires 'ppscore' library\n",
    "print(\"=== Predictive Power Analysis ===\")\n",
    "\n",
    "# Calculate predictive relationships for categorical variables\n",
    "# Using chi-square test approach\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Check relationship between education and income\n",
    "print(\"\\nEducation vs Income:\")\n",
    "contingency_table = pd.crosstab(df['education'], df['income'])\n",
    "chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "print(\"Chi-square statistic:\", round(chi2, 2))\n",
    "print(\"P-value:\", p_value)\n",
    "if p_value < 0.05:\n",
    "    print(\"Result: Strong relationship exists!\")\n",
    "\n",
    "# Check relationship between occupation and income\n",
    "print(\"\\nOccupation vs Income:\")\n",
    "contingency_table = pd.crosstab(df['occupation'], df['income'])\n",
    "chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "print(\"Chi-square statistic:\", round(chi2, 2))\n",
    "print(\"P-value:\", p_value)\n",
    "if p_value < 0.05:\n",
    "    print(\"Result: Strong relationship exists!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Comparison: Correlation vs PPS ===\n",
      "\n",
      "Correlation Matrix:\n",
      "- Only measures LINEAR relationships\n",
      "- Works only with numerical variables\n",
      "- Symmetric (A,B) = (B,A)\n",
      "\n",
      "PPS (Predictive Power Score):\n",
      "- Measures ANY relationship (linear or non-linear)\n",
      "- Works with categorical AND numerical variables\n",
      "- Asymmetric (A predicting B may differ from B predicting A)\n",
      "\n",
      "Key Finding: Variables like education and occupation\n",
      "show strong predictive power for income even though\n",
      "they can't be measured using simple correlation.\n"
     ]
    }
   ],
   "source": [
    "# Compare findings\n",
    "print(\"=== Comparison: Correlation vs PPS ===\")\n",
    "print()\n",
    "print(\"Correlation Matrix:\")\n",
    "print(\"- Only measures LINEAR relationships\")\n",
    "print(\"- Works only with numerical variables\")\n",
    "print(\"- Symmetric (A,B) = (B,A)\")\n",
    "print()\n",
    "print(\"PPS (Predictive Power Score):\")\n",
    "print(\"- Measures ANY relationship (linear or non-linear)\")\n",
    "print(\"- Works with categorical AND numerical variables\")\n",
    "print(\"- Asymmetric (A predicting B may differ from B predicting A)\")\n",
    "print()\n",
    "print(\"Key Finding: Variables like education and occupation\")\n",
    "print(\"show strong predictive power for income even though\")\n",
    "print(\"they can't be measured using simple correlation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "In this assignment, we learned:\n",
    "\n",
    "1. **Data Preprocessing:**\n",
    "   - Handling missing values (imputation with mode)\n",
    "   - Scaling: Standard (mean=0, std=1) vs Min-Max (range 0-1)\n",
    "\n",
    "2. **Encoding:**\n",
    "   - One-Hot: For categorical with few categories\n",
    "   - Label: For categorical with many categories\n",
    "\n",
    "3. **Feature Engineering:**\n",
    "   - Created total_capital (net capital change)\n",
    "   - Created age_group (categorized ages)\n",
    "   - Applied log transformation to reduce skewness\n",
    "\n",
    "4. **Feature Selection:**\n",
    "   - Isolation Forest to detect and remove outliers\n",
    "   - Correlation matrix for linear relationships\n",
    "   - PPS for capturing all types of relationships"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
